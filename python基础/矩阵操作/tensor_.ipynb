{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意读进来的图片，pytorch自动加载的图片第一个通道是颜色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 1667, 4)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "img = Image.open(r\"D:\\deeplearning\\pytorch_同济\\028_034：图像识别核心模块实战解读\\卷积网络实战\\1.png\")\n",
    "img = np.array(img)\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 258, 3)\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(r\"D:\\deeplearning\\pytorch_indoor\\data\\faces\\10comm-decarlo.jpg\")\n",
    "img = np.array(img)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shape 和 size（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 4, 2])\n",
      "torch.Size([3, 4, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x = torch.randn(3,2,5,4,device=device)\n",
    "#print(x)\n",
    "\n",
    "conv = torch.nn.Conv2d(2,4,(2,3),device=device)\n",
    "res = conv(x)\n",
    "\n",
    "print(res.shape)    # torch.Size([3, 4, 4, 2])\n",
    "print(res.size()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n",
      "torch.Size([4, 1])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data=[[1,2],[3,4]]\n",
    "tensor=torch.FloatTensor(data)\n",
    "print(tensor.reshape(4,1))\n",
    "print(tensor.reshape(4,1).size())\n",
    "print(tensor.view(-1,2))    # tensor.view()方法可以调整tensor的形状，但必须保证调整前后元素总数一致。\n",
    "                            # view不会修改自身的数据，返回的新tensor与原tensor共享内存，即更改一个，另一个也随之改变\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解除梯度和复制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2603,  0.9908],\n",
      "        [-0.3400, -1.3018],\n",
      "        [ 0.9738,  0.5514]], device='cuda:0')\n",
      "tensor([[-1.2603,  0.9908],\n",
      "        [-0.3400, -1.3018],\n",
      "        [ 0.9738,  0.5514]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,2,device=device)\n",
    "print(x)\n",
    "x = x.to(\"cpu\").clone().detach()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np_data=np.arange(6).reshape((2,3))\n",
    "torch_data=torch.tensor([1,2,3],dtype=torch.int32)\n",
    "\n",
    "print(np_data)\n",
    "print(torch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2.],\n",
       "         [3., 4.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反向梯度 requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "tensor=torch.FloatTensor([[1,2],[3,4]])\n",
    "variable=Variable(tensor,requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "反向梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "t_out=torch.mean(tensor*tensor)\n",
    "v_out=torch.mean(variable*variable)\n",
    "v_out.backward()\n",
    "#v_out = 1/4*sum(tensor*tensor)\n",
    "#dv_out/dvar=1/4*2*var\n",
    "print(variable.grad)\n",
    "print(variable)\n",
    "print(variable.data)\n",
    "print(variable.data.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clamp设置最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1227,  0.5728,  0.1618, -1.2737],\n",
      "        [-0.8173, -1.9170,  0.4796, -1.6053],\n",
      "        [ 0.0755, -0.3913,  0.9548, -1.4388],\n",
      "        [ 1.3309, -0.4254,  0.5569, -1.3829]])\n",
      "tensor([[0.0000, 0.5728, 0.1618, 0.0000],\n",
      "        [0.0000, 0.0000, 0.4796, 0.0000],\n",
      "        [0.0755, 0.0000, 0.9548, 0.0000],\n",
      "        [1.3309, 0.0000, 0.5569, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "print(x)\n",
    "x = x.clamp(min=0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 求最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3426,  1.0249,  1.4993,  0.9667],\n",
      "        [-0.1284, -1.7554,  1.1140, -1.4146],\n",
      "        [ 0.6946, -1.3141, -1.3764,  0.6439],\n",
      "        [ 0.0720, -1.1401,  1.1311, -0.8952]])\n",
      "tensor([0.6946, 1.0249, 1.4993, 0.9667]) tensor([2, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "print(x)\n",
    "data, index = torch.max(x, 0)\n",
    "print( data, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy用dot，tensor用mm,但 所以说mm不是简单的点乘，而是自定义的计算和反向梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7890,  1.1075, -0.0646,  0.1637, -0.2212],\n",
      "        [ 0.5036, -0.9684, -1.3050,  0.6992,  1.4138],\n",
      "        [-0.8618, -0.3875, -0.7452, -0.2451,  0.3027],\n",
      "        [-1.3232,  1.4057,  2.3509, -1.6956, -0.9897]], device='cuda:0')\n",
      "tensor([[-0.5545,  0.1147, -0.9228, -1.4858],\n",
      "        [ 0.3888,  0.5982,  1.9038,  0.4557],\n",
      "        [-1.0380,  0.2225,  0.4537,  0.7426]], device='cuda:0')\n",
      "tensor([[ 3.2565, -2.4562, -2.9191,  2.7349,  1.4760],\n",
      "        [-2.2493, -0.2457, -1.1531, -0.7575,  0.8849],\n",
      "        [-0.4426, -0.4971,  1.1843, -1.3847, -0.0535]], device='cuda:0')\n",
      "tensor([[3.2565, 0.0000, 0.0000, 2.7349, 1.4760],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.8849],\n",
      "        [0.0000, 0.0000, 1.1843, 0.0000, 0.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\")\n",
    "N, D_in, H, D_out = 3, 4, 5, 2\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=torch.float)\n",
    "x = torch.randn(N, D_in, device=device, dtype=torch.float)\n",
    "h = x.mm(w1)\n",
    "print(w1)\n",
    "print(x)\n",
    "print(h)\n",
    "print(h.clamp(min=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d533ad8ead974ef2863af58c6dd965ec76a73ec9b0d6bfff6efc64af475660a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
